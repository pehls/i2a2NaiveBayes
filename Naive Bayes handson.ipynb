{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy \n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def _encode(df, labels, label):\n",
    "    \"\"\"\n",
    "        Sempre: \n",
    "            0-HODL\n",
    "            1-BUY\n",
    "            2-SELL\n",
    "    \"\"\"\n",
    "    df[label] = 0\n",
    "    df.loc[df[labels[0]] == 1, label] = 1\n",
    "    df.loc[df[labels[1]] == 1, label] = 2\n",
    "    return df\n",
    "def _final_encode(df, labels, label):\n",
    "    \"\"\"\n",
    "        Sempre: \n",
    "            0-HODL\n",
    "            1-BUY\n",
    "            2-SELL\n",
    "        no caso do final, ação = 1; ver nos indicadores e aplicar a ação escolhida\n",
    "    \"\"\"\n",
    "    df[label] = 0\n",
    "    df[label] = df[labels].sum(axis=1)\n",
    "    df[label] = [ 1 if x.astype(int) > 0 else 0 for x in df[label].values ]\n",
    "    return df\n",
    "def _filter_Train_n_Test(df):\n",
    "    train = df.loc[df.Data < pd.to_datetime(\"01/02/2018\", format=\"%d/%m/%Y\")]\n",
    "    test = df.loc[df.Data >= pd.to_datetime(\"01/02/2018\", format=\"%d/%m/%Y\")]\n",
    "    return train, test\n",
    "def _preprocess(df, X_labels, y_label):\n",
    "    train, test = _filter_Train_n_Test(df)\n",
    "    X_train = train[X_labels]\n",
    "    y_train = train[y_label]\n",
    "    X_test = test[X_labels]\n",
    "    y_test = test[y_label]\n",
    "    scaler = MinMaxScaler()\n",
    "    # Prevenindo data leakage\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler\n",
    "\n",
    "def _apply_gaussianNB(df, features, label, silent=False):\n",
    "    \"\"\"\n",
    "    Basea-se na suposição de que os dados seguem a distribuição normal para a predição da probabilidade a priori.\n",
    "    As features devem ter valores contínuos (caso dos valores de preço!)\n",
    "    \"\"\"\n",
    "    model = GaussianNB()\n",
    "    X_train, y_train, X_test, y_test, scaler = _preprocess(df, features, label)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    if (silent):\n",
    "        return model, scaler\n",
    "    print(y_train.value_counts())\n",
    "    print(\"Accuracy (Model: {} | Gaussian Naive Bayes):\".format(label),metrics.accuracy_score(y_test, y_pred))\n",
    "    return model, scaler\n",
    "\n",
    "def _apply_complementNB(df, features, label, silent=False, _alpha = 1):\n",
    "    \"\"\"\n",
    "    Seguimos a distribuição normal, mas generalizamos a predição calculando a probabilidade do item pertencer a todas as classes.\n",
    "    (calculamos a probabilidade do item não pertencer a cada classe, selecionamos o menor valor, tendo em vista que calculamos a probabilidade de não ser da classe em cálculo)\n",
    "    Útil para datasets desbalanceados!\n",
    "    \"\"\"\n",
    "    model = ComplementNB(alpha=_alpha)\n",
    "    X_train, y_train, X_test, y_test, scaler = _preprocess(df, features, label)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    if (silent):\n",
    "        return model, scaler\n",
    "    print(y_train.value_counts())\n",
    "    print(\"Accuracy (Model: {} | Complement Naive Bayes):\".format(label),metrics.accuracy_score(y_test, y_pred))\n",
    "    return model, scaler\n",
    "\n",
    "def _apply_multinomialNB(df, features, label, silent=False, _alpha = 1):\n",
    "    \"\"\"\n",
    "    Esse algoritmo usa os dados em uma distribuição multinomial, que é uma generalização da distribuição binomial. \n",
    "    Essa distribuição é parametrizada por vetores θyi=(θy1,…,θyn), θyi é a probabilidade do evento i ocorrer, dado que a classe é y\n",
    "    \"\"\"\n",
    "    model = MultinomialNB(alpha=_alpha)\n",
    "    X_train, y_train, X_test, y_test, scaler = _preprocess(df, features, label)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    if (silent):\n",
    "        return model, scaler\n",
    "    print(y_train.value_counts())\n",
    "    print(\"Accuracy (Model: {} | Multinomial Naive Bayes):\".format(label),metrics.accuracy_score(y_test, y_pred))\n",
    "    return model, scaler\n",
    "\n",
    "def _apply_model(df, model, scaler, features, label, decisions):\n",
    "    \"\"\"\n",
    "    Aplica as decisões dos primeiros modelos, para avaliação de como ponderar para uma gestão de risco baseada em resultados anteriores\n",
    "    \"\"\"\n",
    "   # Variáveis de apoio\n",
    "    trades = 0 if len(decisions)==0 else len(decisions) - 1\n",
    "\n",
    "    # Ordenar DF pela data (mais antiga primeiro)\n",
    "    df = df.sort_values('Data', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Separamos as colunas para a análise\n",
    "    cols = copy.deepcopy(features)\n",
    "    cols.append(label)\n",
    "    cols.append('Data')\n",
    "\n",
    "    # Pegamos do df as colunas\n",
    "    features_df = df[cols]\n",
    "\n",
    "    # para cada linha, aplicamos a decisão do modelo\n",
    "    for i, item in df.iterrows():\n",
    "        row_features = scaler.transform(pd.DataFrame(item[features]).T)\n",
    "        _data = item['Data']\n",
    "        if (trades > 0 and decisions.loc[trades-1, 'classifier'] == label):\n",
    "            _last_decision_date = decisions.iloc[trades-1].Data\n",
    "            _last_model_decision = decisions.iloc[trades-1].model_decision\n",
    "            _last_real_decision = decisions.iloc[trades-1].real_decision\n",
    "        else:\n",
    "            _last_decision_date = pd.to_datetime('01/01/1950')\n",
    "            _last_model_decision = 2\n",
    "            _last_real_decision = 2\n",
    "        _classifier = label\n",
    "        _real_decision = item[label]\n",
    "        _model_decision = model.predict(row_features)[0] if label != 'divergency_decisor' else item[label] # No caso do decisor de divergência vamos usar o próprio dado real\n",
    "        _value_fechamento = item['Fechamento']\n",
    "        #se a data atual for maior que a data do ultimo trade e decisao diferente de HOLD e da anterior:\n",
    "        #if ((_model_decision != 0) or (_real_decision != 0)):\n",
    "        if ((_data >= _last_decision_date + timedelta(days=wait_time))):\n",
    "            if ((_model_decision != 0 and _model_decision != _last_model_decision) or (_real_decision != 0 and _real_decision != _last_real_decision)):\n",
    "            # Adicionamos nas decisões os dados de data, classificador, decisao real, decisao do modelo e valor\n",
    "                decisions.loc[trades,'Data'] = _data\n",
    "                decisions.loc[trades,'classifier'] = _classifier\n",
    "                decisions.loc[trades,'real_decision'] = _real_decision\n",
    "                decisions.loc[trades,'model_decision'] = _model_decision\n",
    "                decisions.loc[trades,'value_fechamento'] = _value_fechamento\n",
    "                trades += 1\n",
    "    return decisions\n",
    "\n",
    "def _apply_decisions(model_decisions, classifier, money_start, decision_weight, n):\n",
    "    \"\"\"\n",
    "    Aqui, aplicamos as decisões dos modelos sem uma gestão de risco, para gerar os pesos de ponderação para a gestão de risco;\n",
    "    \"All in, All out!\", ou seja, compramos tudo ou vendemos tudo!\n",
    "    \"\"\"\n",
    "    last_decision = 2\n",
    "    money_atual = money_start\n",
    "    quant_comprada = 0\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(classifier)\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    for i, row in model_decisions.iterrows():\n",
    "        if (row.model_decision != last_decision and row.model_decision !=0):\n",
    "            last_decision = row.model_decision\n",
    "            if (last_decision == 1):\n",
    "                quant_comprada = float(money_atual) / float(row.value_fechamento)\n",
    "                money_atual = float(money_atual) - (float(quant_comprada) * float(row.value_fechamento))\n",
    "                print(\"Decisão de compra -\")\n",
    "                print('Valor: {}'.format(str(row.value_fechamento)))\n",
    "                print('Quantidade comprada: {}'.format(str(quant_comprada)))\n",
    "                print(\"Money atual: {}\".format(str(money_atual)))\n",
    "            elif (last_decision == 2):\n",
    "                money_comprado = float(quant_comprada) * float(row.value_fechamento)\n",
    "                money_atual = float(money_atual) + float(money_comprado)\n",
    "                print(\"Decisão de venda -\")\n",
    "                print('Valor: {}'.format(str(row.value_fechamento)))\n",
    "                print('Quantidade vendida: {}'.format(str(quant_comprada)))\n",
    "                print(\"Money atual: {}\".format(str(money_atual)))\n",
    "            else:\n",
    "                print(\"HODL!\")\n",
    "        else:\n",
    "            print(\"HODL!\")\n",
    "    if (last_decision == 1):\n",
    "         money_atual = float(quant_comprada) * float(row.value_fechamento)\n",
    "    decision_weight.loc[n, 'classifier'] = classifier\n",
    "    decision_weight.loc[n, 'initial_maney'] = money_start\n",
    "    decision_weight.loc[n, 'final_maney'] = money_atual\n",
    "    decision_weight.loc[n, 'lucro_percentual'] = (money_atual - money_start)/money_start\n",
    "    return decision_weight\n",
    "\n",
    "def _apply_decisions_withperc(model_decisions, money_start, silent_mode=True):\n",
    "    \"\"\"\n",
    "    Aplica as decisoes encontradas utilizando a ponderação dos melhores valores como método de gestão de risco\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(columns = ['Data','initial_maney','final_maney','quant_hold','value_fechamento','perc_usado', 'action'])\n",
    "    last_decision = 2\n",
    "    money_atual = money_start\n",
    "    quant_comprada = 0\n",
    "    trades = 0\n",
    "    for i, row in model_decisions.iterrows():\n",
    "        if (row.real_decision != last_decision and row.real_decision !=0):\n",
    "            data = row.Data\n",
    "            last_decision = row.real_decision\n",
    "            if (last_decision == 1):\n",
    "                action='compra'\n",
    "                money = float(money_atual) * float(row.perc_aplicado)\n",
    "                quant_acomprar = (float(money) / float(row.value_fechamento))\n",
    "                quant_comprada = quant_comprada + quant_acomprar\n",
    "                money_atual = float(money_atual) - (money)\n",
    "                if (silent_mode==False):\n",
    "                    print(\"--------------------------\")\n",
    "                    print(\"Decisão de compra -\")\n",
    "                    print('Valor: {}'.format(str(row.value_fechamento)))\n",
    "                    print('Quantidade comprada: {}'.format(str(quant_acomprar)))\n",
    "                    print('Quantidade em hold: '+str(quant_comprada))\n",
    "                    print(\"Money atual: {}\".format(str(money_atual)))\n",
    "\n",
    "            elif (last_decision == 2):\n",
    "                action='venda'\n",
    "                quant_vender = float(quant_comprada) * float(row.perc_aplicado)\n",
    "                quant_comprada = float(quant_comprada) - float(quant_vender)\n",
    "                money_comprado = float(quant_vender) * float(row.value_fechamento)\n",
    "                money_atual = float(money_atual) + float(money_comprado)\n",
    "                if (silent_mode==False):\n",
    "                    print(\"--------------------------\")\n",
    "                    print(\"Decisão de venda -\")\n",
    "                    print('Valor: {}'.format(str(row.value_fechamento)))\n",
    "                    print('Quantidade vendida: {}'.format(str(quant_vender)))\n",
    "                    print('Quantidade em hold: '+str(quant_comprada))\n",
    "                    print(\"Money atual: {}\".format(str(money_atual)))\n",
    "            else:\n",
    "                if (silent_mode==False):\n",
    "                    print(\"HODL!\")\n",
    "        else:\n",
    "            if (silent_mode==False):\n",
    "                print(\"HODL!\")\n",
    "        results.loc[trades, 'Data'] = data\n",
    "        results.loc[trades, 'initial_maney'] = money_start\n",
    "        results.loc[trades, 'final_maney'] = money_atual\n",
    "        results.loc[trades, 'quant_hold'] = quant_comprada\n",
    "        results.loc[trades, 'value_fechamento'] = float(row.value_fechamento)\n",
    "        results.loc[trades, 'perc_usado'] = float(row.perc_aplicado)\n",
    "        results.loc[trades, 'action'] = action\n",
    "        trades +=1\n",
    "    if (last_decision == 1 or quant_comprada > 0):\n",
    "        money_atual = money_atual + (float(quant_comprada) * float(row.value_fechamento))\n",
    "        quant_comprada = 0\n",
    "        results.loc[trades, 'Data'] = data\n",
    "        results.loc[trades, 'initial_maney'] = money_start\n",
    "        results.loc[trades, 'final_maney'] = money_atual\n",
    "        results.loc[trades, 'quant_hold'] = quant_comprada\n",
    "        results.loc[trades, 'value_fechamento'] = float(row.value_fechamento)\n",
    "        results.loc[trades, 'perc_usado'] = float(row.perc_aplicado)\n",
    "        results.loc[trades, 'action'] = 'final'\n",
    "    return results\n",
    "\n",
    "def _get_model_decisions(df, classifiers, scalers, models, wait_time=5, silent_mode=True):\n",
    "    \"\"\"\n",
    "    Aqui, utilizando os modelos encontrados:\n",
    "        -verificamos quantos modelos consideram cada ação (buy, hold, sell),\n",
    "        -caso todos consiredem hold, não faz nada;\n",
    "        -caso a maioria seja buy/sell, compramos com a soma da ponderação encontrada a partir dos resultados anteriores\n",
    "    \"\"\"\n",
    "    decisions = pd.DataFrame(columns=['Data','real_decision','value_fechamento','perc_aplicado'])\n",
    "    # Variáveis de apoio\n",
    "    trades = 0\n",
    "\n",
    "    # Ordenar DF pela data (mais antiga primeiro)\n",
    "    df = df.sort_values('Data', ascending=True).reset_index(drop=True)\n",
    "    for i, item in df.iterrows():\n",
    "        _buy = []\n",
    "        _sell = []\n",
    "        _hold = []\n",
    "        _value_fechamento = item['Fechamento']\n",
    "        for classifier in classifiers:\n",
    "            row_features = scalers.get(\n",
    "                classifier\n",
    "            ).transform(\n",
    "                pd.DataFrame(\n",
    "                    item[features.get(classifier)]\n",
    "                ).T\n",
    "            )\n",
    "            _model_decision = (models.get(classifier).predict(row_features)[0] if classifier != 'divergency_decisor' else item[classifier])\n",
    "            if (_model_decision == 1):\n",
    "                _buy.append(decision_weight.loc[decision_weight.classifier == classifier,'new_weight'].values[0])\n",
    "            elif (_model_decision == 2):\n",
    "                _sell.append(decision_weight.loc[decision_weight.classifier == classifier,'new_weight'].values[0])\n",
    "            else:\n",
    "                _hold.append(1)\n",
    "        if (len(_hold) == 4):\n",
    "            _model_decision = 0\n",
    "            perc_ = 0\n",
    "        elif (len(_buy) > len(_sell)):\n",
    "            _model_decision = 1\n",
    "            perc_ = sum(_buy)\n",
    "            _data = item['Data']\n",
    "\n",
    "        else:\n",
    "            _model_decision = 2\n",
    "            perc_ = sum(_sell)\n",
    "            _data = item['Data']\n",
    "\n",
    "        if (perc_ > 0):\n",
    "            if (trades > 0):\n",
    "                _last_decision_date = decisions.iloc[trades-1].Data\n",
    "                _last_real_decision = decisions.iloc[trades-1].real_decision\n",
    "            else:\n",
    "                _last_decision_date = pd.to_datetime('01/01/1950')\n",
    "                _last_real_decision = 2\n",
    "            #se a data atual for maior que a data do ultimo trade e decisao diferente de HOLD e da anterior:\n",
    "            #if ((_model_decision != 0) or (_real_decision != 0)):\n",
    "            if ((_data >= _last_decision_date + timedelta(days=wait_time))):\n",
    "                if ((_model_decision != 0 and _model_decision != _last_real_decision)):\n",
    "                # Adicionamos nas decisões os dados de data, classificador, decisao real, decisao do modelo e valor\n",
    "                    new_decision = {\n",
    "                        'Data':_data,\n",
    "                        'real_decision':_model_decision,\n",
    "                        'value_fechamento':_value_fechamento,\n",
    "                        'perc_aplicado':perc_}\n",
    "                    decisions = decisions.append(new_decision, ignore_index=True)\n",
    "                    trades += 1\n",
    "    return decisions\n",
    "\n",
    "def _get_final_decisions(df, _stop_loss, _sell_by_stoploss, wait_time, final_scaler, final_model, classifiers, scalers, models):\n",
    "    \"\"\"\n",
    "        -Função final com modelo de trade!\n",
    "        Iremos, utilizando os suportes como stop loss, e quando encontrar um preço de fechamento \n",
    "    igual ou menor ao suporte em um ponto de suporte, a venda de x% (definido pela var _sell_by_stoploss), aplicar os modelos encontrados quando o modelo final decidir agir.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Variáveis de apoio\n",
    "    trades = 0\n",
    "    _last_decision_date = pd.to_datetime('01/01/1950')\n",
    "    _last_real_decision = 2\n",
    "    decisions = pd.DataFrame(columns=['Data','real_decision','value_fechamento','perc_aplicado','stop_loss','final_model', 'holds','buys','sells'])\n",
    "    # Ordenar DF pela data (mais antiga primeiro)\n",
    "    df = df.sort_values('Data', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    for i, item in df.iterrows():\n",
    "        _buy = []\n",
    "        _sell = []\n",
    "        _hold = []\n",
    "        final_hold = 1\n",
    "        _value_fechamento = item['Fechamento']\n",
    "        if (item['Suporte ']==1):\n",
    "            _stop_loss = item['Mínimo']\n",
    "        row_features = final_scaler.transform(pd.DataFrame(item[final_features]).T)\n",
    "        _model_decision = final_model.predict(row_features)[0] ## Pegamos a decisão do modelo geral\n",
    "        decisao_modelo_final = final_model.predict(row_features)[0]\n",
    "        if (_model_decision == 1): ## se for uma decisão de ação,\n",
    "            final_hold = 0\n",
    "            for classifier in classifiers: ## aplicaremos os modelos criados anteriormente\n",
    "                row_features = scalers.get(\n",
    "                    classifier\n",
    "                ).transform(\n",
    "                    pd.DataFrame(\n",
    "                        item[features.get(classifier)]\n",
    "                    ).T\n",
    "                )\n",
    "                _model_decision = (models.get(classifier).predict(row_features)[0] if classifier != 'divergency_decisor' else item[classifier])\n",
    "                if (_model_decision == 1):\n",
    "                    _buy.append(decision_weight.loc[decision_weight.classifier == classifier,'new_weight'].values[0])\n",
    "                elif (_model_decision == 2):\n",
    "                    _sell.append(decision_weight.loc[decision_weight.classifier == classifier,'new_weight'].values[0])\n",
    "                else:\n",
    "                    _hold.append(decision_weight.loc[decision_weight.classifier == classifier,'new_weight'].values[0])\n",
    "        else:\n",
    "            final_hold = 1\n",
    "            _model_decision = 0\n",
    "            perc_ = 0\n",
    "        if (decisao_modelo_final == 0): ## Usamos um comitê dos decisores: o mais votado, vira a ação! caso o modelo inicial seja hold, aplica:\n",
    "            _model_decision = 0\n",
    "            perc_ = 0\n",
    "            _data = item['Data']\n",
    "        elif (len(_buy) > len(_sell)):\n",
    "            _model_decision = 1\n",
    "            perc_ = sum(_buy)\n",
    "            _data = item['Data']\n",
    "        elif (len(_sell) > len(_buy)):\n",
    "            _model_decision = 2\n",
    "            perc_ = sum(_sell)\n",
    "            _data = item['Data']\n",
    "        else:\n",
    "            _model_decision = 0\n",
    "            perc_ = 0\n",
    "            _data = item['Data']\n",
    "\n",
    "        if (_model_decision > 0):\n",
    "            if (trades > 0):\n",
    "                _last_decision_date =  pd.to_datetime(decisions.tail(1).Data.values[0])\n",
    "                _last_real_decision = decisions.tail(1).real_decision.values[0]\n",
    "        #se a data atual for maior que a data do ultimo trade e decisao diferente de HOLD e da anterior:\n",
    "        #if ((_model_decision != 0) or (_real_decision != 0)):\n",
    "        if ((_data >= _last_decision_date + timedelta(days=wait_time))):\n",
    "            if (_value_fechamento <= _stop_loss and item['Suporte ']==1): #se encontrarmos um preço de fechamento menor ou igual ao suporte e um ponto de suporte, vendemos x%\n",
    "                _model_decision = 2\n",
    "                perc_ = _sell_by_stoploss\n",
    "                new_decision = {\n",
    "                    'Data':_data,\n",
    "                    'real_decision':_model_decision,\n",
    "                    'value_fechamento':_value_fechamento,\n",
    "                    'perc_aplicado':perc_,\n",
    "                    'stop_loss':_stop_loss,\n",
    "                    'holds':len(_hold),\n",
    "                    'buys':len(_buy),\n",
    "                    'sells':len(_sell),\n",
    "                    'final_model':decisao_modelo_final}\n",
    "                decisions = decisions.append(new_decision, ignore_index=True)\n",
    "                trades += 1\n",
    "            elif ((_model_decision != 0 and _model_decision != _last_real_decision)):\n",
    "            # Adicionamos nas decisões os dados de data, classificador, decisao real, decisao do modelo e valor\n",
    "                new_decision = {\n",
    "                    'Data':_data,\n",
    "                    'real_decision':_model_decision,\n",
    "                    'value_fechamento':_value_fechamento,\n",
    "                    'perc_aplicado':perc_,\n",
    "                    'stop_loss':_stop_loss,\n",
    "                    'holds':len(_hold),\n",
    "                    'buys':len(_buy),\n",
    "                    'sells':len(_sell),\n",
    "                    'final_model':decisao_modelo_final}\n",
    "                decisions = decisions.append(new_decision, ignore_index=True)\n",
    "                trades += 1\n",
    "    return decisions\n",
    "\n",
    "def _print_decisions(decisions):\n",
    "    \"\"\"\n",
    "    Função auxiliar para printar as decisões\n",
    "    \"\"\"\n",
    "    print(\"Data inicial: {}\".format(decisions.head(1).Data.values[0]))\n",
    "    print(\"Dinheiro inicial: R${:.2f}\".format(decisions.tail(1).initial_maney.values[0]))\n",
    "    print(\"Data final: {}\".format(decisions.tail(1).Data.values[0]))\n",
    "    print(\"Dinheiro final: R${:.2f}\".format(decisions.tail(1).final_maney.values[0]))\n",
    "    print(\"Lucro final (treino): {:.2f}%\".format((decisions.tail(1).initial_maney.values[0] / decisions.tail(1).final_maney.values[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./database/indicadores petrobras_fase 1_ v1.2.xlsx\", sheet_name = \"Tendencias\").drop(['-','--'], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Willians\n",
    "features = ['Fechamento','Var.Dia (%)','Abertura','Mínimo','Máximo','IBOVESPA','22D ROLLING BETA ',\n",
    "             'Suporte ','Resistencia','Hammer','William %R']\n",
    "labels = ['Willians Buy','Willians Sell']\n",
    "label = 'Willians_decisor' \n",
    "df = _encode(df, labels, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    '''\n",
    "    Bayes Theorem form\n",
    "    P(y|X) = P(X|y) * P(y) / P(X)\n",
    "    '''\n",
    "    def calc_prior(self, features, target):\n",
    "        '''\n",
    "        prior probability P(y)\n",
    "        calculate prior probabilities\n",
    "        '''\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "        '''\n",
    "        calculate mean, variance for each column and convert to numpy array\n",
    "        ''' \n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "              \n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "        '''\n",
    "        calculate probability from gaussian density function (normally distributed)\n",
    "        we will assume that probability of specific target value given specific class is normally distributed \n",
    "        \n",
    "        probability density function derived from wikipedia:\n",
    "        (1/√2pi*σ) * exp((-1/2)*((x-μ)^2)/(2*σ²)), where μ is mean, σ² is variance, σ is quare root of variance (standard deviation)\n",
    "        '''\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "#         numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i]) ## use the log to make it more numerically stable\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x))) # use the log to make it more numerically stable\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        # return class with highest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return accuracy\n",
    "\n",
    "    def visualize(self, y_true, y_pred, target):\n",
    "        \n",
    "        tr = pd.DataFrame(data=y_true, columns=[target])\n",
    "        pr = pd.DataFrame(data=y_pred, columns=[target])\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(15,6))\n",
    "        \n",
    "        sns.countplot(x=target, data=tr, ax=ax[0], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        sns.countplot(x=target, data=pr, ax=ax[1], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        \n",
    "\n",
    "        fig.suptitle('True vs Predicted Comparison', fontsize=20)\n",
    "\n",
    "        ax[0].tick_params(labelsize=12)\n",
    "        ax[1].tick_params(labelsize=12)\n",
    "        ax[0].set_title(\"True values\", fontsize=18)\n",
    "        ax[1].set_title(\"Predicted values\", fontsize=18)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-584e6dab00c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-1ed5bba79452>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-1ed5bba79452>\u001b[0m in \u001b[0;36mcalc_statistics\u001b[1;34m(self, features, target)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mcalculate\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mto\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         ''' \n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesClassifier()\n",
    "X_train, y_train, X_test, y_test, scaler = _preprocess(df, features, label)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "if (silent):\n",
    "    return model, scaler\n",
    "print(y_train.value_counts())\n",
    "print(\"Accuracy (Model: {} | Gaussian Naive Bayes):\".format(label),metrics.accuracy_score(y_test, y_pred))\n",
    "return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98529412, 0.52559301, 0.99774944, ..., 0.        , 0.        ,\n",
       "        0.89310345],\n",
       "       [0.97132353, 0.43539326, 1.        , ..., 0.        , 0.        ,\n",
       "        0.83108108],\n",
       "       [0.99485294, 0.47940075, 0.99324831, ..., 1.        , 0.        ,\n",
       "        0.93918919],\n",
       "       ...,\n",
       "       [0.02941176, 0.59519351, 0.02025506, ..., 0.        , 0.        ,\n",
       "        0.95575221],\n",
       "       [0.01764706, 0.66479401, 0.00450113, ..., 0.        , 0.        ,\n",
       "        0.87619048],\n",
       "       [0.        , 0.47908864, 0.        , ..., 0.        , 0.        ,\n",
       "        0.64761905]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
